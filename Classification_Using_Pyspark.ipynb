{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25716bab",
   "metadata": {},
   "source": [
    "# Creating SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be3fac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DP6RA8B:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x209dc07eac8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877c769",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f8778e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-----+-------+--------+------+--------+\n",
      "|buying|maintainence|doors|persons|lug_boot|safety|car_type|\n",
      "+------+------------+-----+-------+--------+------+--------+\n",
      "| vhigh|       vhigh|    2|      2|   small|   low|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|   small|   med|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|   small|  high|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|     med|   low|   unacc|\n",
      "| vhigh|       vhigh|    2|      2|     med|   med|   unacc|\n",
      "+------+------------+-----+-------+--------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"car_data.csv\",inferSchema=True, header=True)\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987cf5eb",
   "metadata": {},
   "source": [
    "# Schema of this DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5648d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- buying: string (nullable = true)\n",
      " |-- maintainence: string (nullable = true)\n",
      " |-- doors: string (nullable = true)\n",
      " |-- persons: string (nullable = true)\n",
      " |-- lug_boot: string (nullable = true)\n",
      " |-- safety: string (nullable = true)\n",
      " |-- car_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d2c7f",
   "metadata": {},
   "source": [
    "# Encoding String Columns into Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcca9179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+\n",
      "|buying_encoded|doors_encoded|maintainence_encoded|persons_encoded|lug_boot_encoded|safety_encoded|car_type_encoded|\n",
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+\n",
      "|             3|            0|                   3|              0|               2|             1|               0|\n",
      "|             3|            0|                   3|              0|               2|             2|               0|\n",
      "|             3|            0|                   3|              0|               2|             0|               0|\n",
      "|             3|            0|                   3|              0|               1|             1|               0|\n",
      "|             3|            0|                   3|              0|               1|             2|               0|\n",
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "categoricalColumns = [\"buying\",\"maintainence\",\"doors\",\"persons\",\"lug_boot\",\"safety\",\"car_type\"]\n",
    "l = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol+\"_encoded\").fit(df_pyspark)\n",
    "    df_pyspark = stringIndexer.transform(df_pyspark)\n",
    "    df_pyspark = df_pyspark.withColumn(categoricalCol+\"_encoded\", df_pyspark[categoricalCol+\"_encoded\"].cast('int'))\n",
    "encoded_df =  df_pyspark.select(\"buying_encoded\",\"doors_encoded\",\"maintainence_encoded\",\"persons_encoded\",\"lug_boot_encoded\",\"safety_encoded\",\"car_type_encoded\")\n",
    "encoded_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334778df",
   "metadata": {},
   "source": [
    "# Feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ac8962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|            features|car_type_encoded|\n",
      "+--------------------+----------------+\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "|[3.0,0.0,3.0,0.0,...|               0|\n",
      "+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureAssembler = VectorAssembler(inputCols=[\"buying_encoded\",\"doors_encoded\",\"maintainence_encoded\",\"persons_encoded\",\"lug_boot_encoded\",\"safety_encoded\"],outputCol=\"features\")\n",
    "output = featureAssembler.transform(encoded_df)\n",
    "output.select(\"features\",\"car_type_encoded\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c823d8",
   "metadata": {},
   "source": [
    "# Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978d1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = output.randomSplit([0.8, 0.2], seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfa0d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data:  1377\n",
      "Size of testing data:  351\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of training data: \",train.count())\n",
    "print(\"Size of testing data: \",test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553dafa5",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e1b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'car_type_encoded', maxIter=10)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01aab322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+-------------------+--------------------+--------------------+----------+\n",
      "|buying_encoded|doors_encoded|maintainence_encoded|persons_encoded|lug_boot_encoded|safety_encoded|car_type_encoded|           features|       rawPrediction|         probability|prediction|\n",
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+-------------------+--------------------+--------------------+----------+\n",
      "|             0|            0|                   0|              0|               0|             0|               0|          (6,[],[])|[1.99198136762971...|[0.76125517518711...|       0.0|\n",
      "|             0|            0|                   0|              0|               2|             0|               0|      (6,[4],[2.0])|[3.26816128608158...|[0.90473344519298...|       0.0|\n",
      "|             0|            0|                   0|              1|               0|             2|               1|(6,[3,5],[1.0,2.0])|[3.15138940343142...|[0.70074537804715...|       0.0|\n",
      "|             0|            0|                   0|              2|               0|             2|               1|(6,[3,5],[2.0,2.0])|[2.05830537339734...|[0.38137779317688...|       1.0|\n",
      "|             0|            0|                   0|              2|               1|             0|               1|(6,[3,4],[2.0,1.0])|[0.44390326678748...|[0.30253957413615...|       1.0|\n",
      "+--------------+-------------+--------------------+---------------+----------------+--------------+----------------+-------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(test)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9e460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC:  0.5901985607326307\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setLabelCol(\"car_type_encoded\")\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "evaluator.evaluate(predictions)\n",
    "print(\"Test Area Under ROC: \",evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a46c48",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "508be299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC:  0.7398590195812419\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Training Model\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'car_type_encoded', maxDepth = 3)\n",
    "dtModel = dt.fit(train)\n",
    "\n",
    "#Prediction\n",
    "predictions = dtModel.transform(test)\n",
    "\n",
    "#Evaluating the performance\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setLabelCol(\"car_type_encoded\")\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "print(\"Test Area Under ROC: \",evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dbd42a",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60e0f78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC:  0.9858482629300609\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Training Model\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'car_type_encoded', numTrees = 500, maxDepth = 10)\n",
    "rfModel = rf.fit(train)\n",
    "\n",
    "#Prediction\n",
    "predictions = rfModel.transform(test)\n",
    "\n",
    "#Evaluating the performance\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "evaluator.setLabelCol(\"car_type_encoded\")\n",
    "evaluator.setPredictionCol(\"prediction\")\n",
    "print(\"Test Area Under ROC: \",evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98b9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
